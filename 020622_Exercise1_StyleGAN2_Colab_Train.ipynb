{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "020622_Exercise1_StyleGAN2-Colab-Train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zxzxzx131313/S22_neural_bodies_StyleGan2/blob/main/020622_Exercise1_StyleGAN2_Colab_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEx9IOnF1hKO"
      },
      "source": [
        "#Training StyleGAN2 on Colab\n",
        "If it were me I’d sign up for Colab Pro ($10/month) to get a couple extra hours of training time in per session. The notebook is broken up into a couple of parts the first is training the network. Then testing it with a latent walk. Before we get into too many details of the process - here are the main steps of generating the walk. \n",
        "- Get the StyleGAN2 repo so that we can use the scripts from it\n",
        "- Get the training dataset, this is what you scrape and stuff\n",
        "- Then we point the model from the repo and train a model\n",
        "- Lastly we generate images which are a walk in this latent space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcDHP4h-11Ii"
      },
      "source": [
        "##Mounting Google Drive\n",
        "So connect up to your google drive so that you can download the repo directly into your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJazuNYurryY"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aadrbMyR2F00"
      },
      "source": [
        "##Install the repo\n",
        "**Only do this for the first time ever setting this up!**\n",
        "\n",
        "If this is your first time ever running this notebook, you’ll want to install my fork of StyleGAN2 to your Drive account. Make sure you have ample space on your Drive (I’d say at least 50GB). This will install the repo and add some dependecies (like transferring from FFHQ the first time).\n",
        "\n",
        "Every time after your first use of this notebook you’ll want to skip this cell and run the cell after this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoTNQ3Gyr0ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e854cfca-a26a-4de5-e07b-cae0f6dfb93f"
      },
      "source": [
        "#SKIP this if you already have a stylegan2 folder in your google drive\n",
        "# this makes a folder \n",
        "%cd /content/drive/My/Drive/\n",
        "!mkdir stylegan2-colab\n",
        "# then we get into the folder\n",
        "%cd stylegan2-colab/\n",
        "# this clones the repository \n",
        "!git clone https://github.com/dvschultz/stylegan2\n",
        "# then we go into the repo\n",
        "%cd stylegan2\n",
        "# then we make a folder called \"pkl\"\n",
        "!mkdir pkl\n",
        "%cd pkl\n",
        "# the gdown commands downloads a file and the ID is whats specified\n",
        "!gdown --id 1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF #inception: https://drive.google.com/open?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n",
        "%cd ../\n",
        "# then make a results drirectory\n",
        "!mkdir results\n",
        "# and under results we would make and navigate to a folder called 00001-pretrained\n",
        "!mkdir results/00001-pretrained\n",
        "%cd results/00001-pretrained\n",
        "# download that too! \n",
        "!gdown --id 1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n",
        "!mv stylegan2-ffhq-config-f.pkl network-snapshot-10000.pkl\n",
        "%cd ../../\n",
        "# lastly make a folder called datasets\n",
        "%mkdir datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My/Drive/'\n",
            "/content/stylegan2-colab/stylegan2\n",
            "/content/stylegan2-colab/stylegan2/stylegan2-colab\n",
            "Cloning into 'stylegan2'...\n",
            "remote: Enumerating objects: 552, done.\u001b[K\n",
            "remote: Total 552 (delta 0), reused 0 (delta 0), pack-reused 552\u001b[K\n",
            "Receiving objects: 100% (552/552), 22.47 MiB | 32.64 MiB/s, done.\n",
            "Resolving deltas: 100% (285/285), done.\n",
            "/content/stylegan2-colab/stylegan2/stylegan2-colab/stylegan2\n",
            "/content/stylegan2-colab/stylegan2/stylegan2-colab/stylegan2/pkl\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JLqXE5bGZnlu2BkbLPD5_ZxoO3Nz-AvF\n",
            "To: /content/stylegan2-colab/stylegan2/stylegan2-colab/stylegan2/pkl/inception_v3_features.pkl\n",
            "100% 87.3M/87.3M [00:00<00:00, 166MB/s]\n",
            "/content/stylegan2-colab/stylegan2/stylegan2-colab/stylegan2\n",
            "/content/stylegan2-colab/stylegan2/stylegan2-colab/stylegan2/results/00001-pretrained\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UlDmJVLLnBD9SnLSMXeiZRO6g-OMQCA_\n",
            "To: /content/stylegan2-colab/stylegan2/stylegan2-colab/stylegan2/results/00001-pretrained/stylegan2-ffhq-config-f.pkl\n",
            "100% 382M/382M [00:01<00:00, 257MB/s]\n",
            "/content/stylegan2-colab/stylegan2/stylegan2-colab/stylegan2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN2K68CE27py"
      },
      "source": [
        "##Picking up from a previous session\n",
        "If you already have the StyleGAN2 repo installed in Drive skip the above cell and run the following. This will make sure you have the latest version in case I make updates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8WgjhRFsFJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bcb1bf0-f2bc-442a-eb4a-97f3418f8bc4"
      },
      "source": [
        "#USE this if you already have a stylegan2 folder in google drive\n",
        "%cd /content/drive/My\\ Drive/stylegan2-colab/stylegan2\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/My Drive/stylegan2-colab/stylegan2'\n",
            "/content/stylegan2-colab/stylegan2/stylegan2-colab/stylegan2\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSbEY2pT3TOb"
      },
      "source": [
        "##Make sure Tensorflow 1.15 is set\n",
        "Colab now defaults to Tensorflow 2. Make sure you run this cell to reset it to TF1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdpKY1XODz2"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1pIBZGzZxSA"
      },
      "source": [
        "##Converting your dataset\n",
        "StyleGAN requires you to convert your standard jpg or png images into a new format (.tfrecords). \n",
        "\n",
        "I’ve seen some recommendations to run this command every time you restart your Colab machine. I think if you ahve a small-ish dataset (< 2000 images) that’s probably unnecessary.\n",
        "\n",
        "I recommend you upload your dataset to Google Drive and copy its path from the Drive folder in Colab and paste its path in the below cell.\n",
        "\n",
        "After the `create_from_images` argument you need to pass in two paths. The first path is where the .tfrecords files should be output (just edit the last part to have a unique name). The second path is to the directory of your images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os # this gives a nifty thing to list out directories \n",
        "os.listdir('/content/drive/MyDrive/ChinatownGate_Combined') # just make sure the directoy is right"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "slEn1lQvyRcg",
        "outputId": "f4495e27-0ecf-45a5-9435-f16246de183a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7111c5c61a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m \u001b[0;31m# this gives a nifty thing to list out directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ChinatownGate_Combined'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just make sure the directoy is right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ChinatownGate_Combined'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/stylegan2-colab/stylegan2\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "_Y42BEiKO021",
        "outputId": "4af5a9fe-7cb3-4bd1-e7e6-3aabd319c4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/stylegan2-colab/stylegan2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/stylegan2-colab/stylegan2'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixjcx2-cbTDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc77ca1f-eb8c-4c9f-a61c-90ccb832c633"
      },
      "source": [
        "#2nd argument is where to put your tfrecords files\n",
        "#3rd should point at your image dataset\n",
        "#so an argument looks like this \n",
        "#python dataset_tool.py (the python file) create_from_images (the function) ./datasets/hybrid-512 (the place to dump the TF files) \n",
        "!python dataset_tool.py create_from_images '/content/drive/MyDrive/stylegan2-colab/stylegan2/datasets/NB_test1' '/content/drive/MyDrive/Neural Bodies/Datasets/TA_Meeting_New_Data_set' #Drive/beauxart/01-data/210122-plansectelev-512-stylegan"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from \"/content/drive/MyDrive/Neural Bodies/Datasets/TA_Meeting_New_Data_set\"\n",
            "Error: Input image resolution must be a power-of-two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAfUNG60aRD1"
      },
      "source": [
        "##Training\n",
        "Note: this will require you to restart your Colab machine every 8–16 hours. You’ve been warned!\n",
        "\n",
        "This library is set up to automatically find your latest .pkl file so it should keep re-training and making progress.\n",
        "\n",
        "##Training Options\n",
        "`--dataset`\n",
        "\n",
        "This should be the name you used in the first path when converting your dataset.\n",
        "\n",
        "`--mirror-augment`\n",
        "\n",
        "Using this option loads some images at random mirrored horizontally (left-to-right). This might help if you have a very small dataset.\n",
        "\n",
        "`--metrics`\n",
        "\n",
        "METRICS DON’T MATTER. It’s art! Use your eyes. Set `--metrics=None` and live your life.\n",
        "\n",
        "If you must use metrics, you have a few options. `fid50k`, the default, uses Frechet Inception Distance score. It’s what was used in StyleGAN1 and what most people know. It’s fine for images of animals and things, but it’s not great. `ppl_wend` is what StyleGAN2 prefers and claims to be more accurate. There are a bunch of other options but I’d recommend you stick with those. Note that both of these take 30–45minutes to run every time it runs so that cuts into your training time in Colab."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5 # since we are using an older version of tensorflow -- if the cell after this ones fails run this one."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlpzZA7Y2xyr",
        "outputId": "65d82bd5-0edf-441c-964c-cd5996441b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QrOVqEHaipA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a39905-5f91-4b0f-b378-e08b29f2b01b"
      },
      "source": [
        "!python run_training.py --num-gpus=1 --data-dir=./datasets --config=config-f --dataset=hybrid-512 --mirror-augment=false --metrics=None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Local submit - run_dir: results/00002-stylegan2-hybrid-512-1gpu-config-f\n",
            "dnnlib: Running training.training_loop.training_loop() on localhost...\n",
            "Streaming data using training.dataset.TFRecordDataset...\n",
            "Traceback (most recent call last):\n",
            "  File \"run_training.py\", line 202, in <module>\n",
            "    main()\n",
            "  File \"run_training.py\", line 197, in main\n",
            "    run(**vars(args))\n",
            "  File \"run_training.py\", line 128, in run\n",
            "    dnnlib.submit_run(**kwargs)\n",
            "  File \"/content/drive/MyDrive/stylegan2-colab/stylegan2/dnnlib/submission/submit.py\", line 343, in submit_run\n",
            "    return farm.submit(submit_config, host_run_dir)\n",
            "  File \"/content/drive/MyDrive/stylegan2-colab/stylegan2/dnnlib/submission/internal/local.py\", line 22, in submit\n",
            "    return run_wrapper(submit_config)\n",
            "  File \"/content/drive/MyDrive/stylegan2-colab/stylegan2/dnnlib/submission/submit.py\", line 280, in run_wrapper\n",
            "    run_func_obj(**submit_config.run_func_kwargs)\n",
            "  File \"/content/drive/MyDrive/stylegan2-colab/stylegan2/training/training_loop.py\", line 142, in training_loop\n",
            "    training_set = dataset.load_dataset(data_dir=dnnlib.convert_path(data_dir), verbose=True, **dataset_args)\n",
            "  File \"/content/drive/MyDrive/stylegan2-colab/stylegan2/training/dataset.py\", line 192, in load_dataset\n",
            "    dataset = dnnlib.util.get_obj_by_name(class_name)(**kwargs)\n",
            "  File \"/content/drive/MyDrive/stylegan2-colab/stylegan2/training/dataset.py\", line 53, in __init__\n",
            "    assert os.path.isdir(self.tfrecord_dir)\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQ7U1ftuj_Dc"
      },
      "source": [
        "Once running, your training files will show up in the results folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9vCDt9LRtXl"
      },
      "source": [
        "#Testing the model (generating images)\n",
        "The following command will generate 55 sample images from the model.\n",
        "\n",
        "##Options\n",
        "`--network`\n",
        "\n",
        "Make sure the `--network` argument points to your .pkl file. (My preferred method is to right click on the file in the Files pane to your left and choose `Copy Path`, then paste that into the argument after the `=` sign).\n",
        "\n",
        "`--seeds`\n",
        "\n",
        "This allows you to choose random seeds from the model. Remember that our input to StyleGAN is a 512-dimensional array. These seeds will generate those 512 values. Each seed will generate a different, random array. The same seed value will also always generate the same random array, so we can later use it for other purposes like interpolation.\n",
        "\n",
        "`--truncation-psi`\n",
        "\n",
        "Truncation is a special argument of StyleGAN. Essentially values that are closer to 0 will be more real than numbers further away from 0. I generally recommend a value between `0.5` and `1.0`. `0.5` will give you pretty \"realistic\" results, while `1.0` is likely to give you \"weirder\" results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "oLHnmRj38_gh",
        "outputId": "394f7e0f-11c5-4f15-95d5-52a5e9e8034e"
      },
      "source": [
        "!pip install opensimplex\n",
        "import opensimplex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opensimplex\n",
            "  Downloading opensimplex-0.4.2-py3-none-any.whl (17 kB)\n",
            "Collecting numpy>=1.20\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 28.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy, opensimplex\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lucid 0.3.10 requires umap-learn, which is not installed.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.4.0 which is incompatible.\n",
            "lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.21.5 which is incompatible.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.5 opensimplex-0.4.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.listdir('/content/drive/MyDrive/stylegan2-colab/stylegan2/results/00001-pretrained') #network-snapshot-10000.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvJGyIL44ul5",
        "outputId": "46da1640-733d-4ed9-96a6-127deca42653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['network-snapshot-10000.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3MhXEAMOMXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5a2b10-fb00-4df6-a760-0f4bdf11e192"
      },
      "source": [
        "!python run_generator.py generate-images --network=/content/drive/MyDrive/stylegan2-colab/stylegan2/results/00001-pretrained/network-snapshot-10000.pkl --seeds=0-1000 --truncation-psi=0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'run_generator.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMiqkA3IReZB"
      },
      "source": [
        "Let’s zip the generated files and download them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tp8O01O3PlFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4aaee15-7410-435b-fddc-1816ee77427c"
      },
      "source": [
        "# check the folder which has the images in it  - in this case it is 00004-generate-images\n",
        "!zip -r generated-0.7.zip /content/drive/MyDrive/stylegan2-colab/stylegan2/results/00004-generate-images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: /content/drive/MyDrive/stylegan2-colab/stylegan2/results/00004-generate-images\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r generated-0.7.zip . -i /content/drive/MyDrive/stylegan2-colab/stylegan2/results/00004-generate-images)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTwJjmCrlfAc"
      },
      "source": [
        "##Interpolation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ2rYIC4TdaJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01473e76-8000-4647-a932-e27d65706c8b"
      },
      "source": [
        "!python run_generator.py generate-latent-walk --network=/content/drive/MyDrive/stylegan2-colab/stylegan2/results/00001-pretrained/network-snapshot-10000.pkl --seeds=0,3,10,13,17,38,42,43,46,48,55,63,67,69,85,88,92,97,98,99,117,119,124,137,139,141,146,152,156,160,173,177,180,189,191,195,198,203,205,212,220,221,228,230,247,267,271,290,292,293,297,300,301,302,306,309,316,318,319,321,324,332,338,340,364,365,371,393,396,427,435,450,458,459,465,468,469,471,487,493,497,498,499,505,516,521,523,525,542,543,548,573,576,577,588,593,597,621,622,627,632,637,657,694,695,704,705,707,712,713,724,726,737,739,752,761,771,779,780,789,797,0\t --frames 7192 --truncation-psi=0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'run_generator.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dceBSxTsmW1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c88d003-c77c-4d40-a5fe-cb03a413e2c4"
      },
      "source": [
        "#convert to video \n",
        "!ffmpeg -r 24 -i /content/drive/MyDrive/stylegan2-colab/stylegan2/results/00005-generate-latent-walk/frame%05d.png -vcodec libx264 -pix_fmt yuv420p latent-walk-sectelev.mp4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '/content/drive/MyDrive/stylegan2-colab/stylegan2/results/00005-generate-latent-walk/frame%05d.png':\n",
            "  Duration: 00:04:50.40, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 1024x1024, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mprofile High, level 3.2\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=24 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'latent-walk-sectelev.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1024x1024, q=-1--1, 24 fps, 12288 tbn, 24 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
            "frame= 7260 fps= 24 q=-1.0 Lsize=  108208kB time=00:05:02.37 bitrate=2931.6kbits/s speed=1.01x    \n",
            "video:108127kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.075501%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mframe I:30    Avg QP:21.02  size: 75528\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mframe P:2553  Avg QP:23.67  size: 30954\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mframe B:4677  Avg QP:26.32  size:  6292\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mconsecutive B-frames: 13.6%  1.3%  1.1% 84.1%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mmb I  I16..4:  7.6% 75.4% 17.0%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mmb P  I16..4:  3.6% 17.7%  2.7%  P16..4: 43.9% 14.6%  7.4%  0.0%  0.0%    skip:10.2%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mmb B  I16..4:  0.3%  0.9%  0.1%  B16..8: 23.5%  2.6%  0.9%  direct: 6.2%  skip:65.6%  L0:33.3% L1:53.1% BI:13.6%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0m8x8 transform intra:73.5% inter:74.6%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mcoded y,uvDC,uvAC intra: 67.0% 63.3% 12.6% inter: 22.3% 21.5% 0.1%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mi16 v,h,dc,p: 28% 16%  7% 49%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 11% 17%  7% 10% 12%  8% 10%  7%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20%  9% 12%  7% 15% 15%  9%  8%  5%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mi8c dc,h,v,p: 55% 16% 22%  7%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mWeighted P-Frames: Y:36.5% UV:21.4%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mref P L0: 56.3% 27.3% 12.7%  3.0%  0.8%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mref B L0: 95.0%  3.7%  1.3%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mref B L1: 99.1%  0.9%\n",
            "\u001b[1;36m[libx264 @ 0x55b3e78c7e00] \u001b[0mkb/s:2928.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7A7jRRGmzhU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7cdce8b6-3ee4-459a-cff8-c787bd016269"
      },
      "source": [
        "# this is to remove the folder\n",
        "#rm -r /content/drive/My Drive/stylegan2-colab-test/stylegan2/results/00002-stylegan2-birdaus-1gpu-config-f"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/drive/My': No such file or directory\n",
            "rm: cannot remove 'Drive/stylegan2-colab-test/stylegan2/results/00002-stylegan2-birdaus-1gpu-config-f': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9UpP_fVdql9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}